{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå D√©j√† pr√©sent, ignor√© : https://amzn.to/4kAxwcV\n",
      "‚ùå D√©j√† pr√©sent, ignor√© : https://amzn.to/3SRG5nK\n",
      "‚ùå D√©j√† pr√©sent, ignor√© : https://amzn.to/3YYZOW6\n",
      "‚ùå D√©j√† pr√©sent, ignor√© : https://amzn.to/4jk2uFe\n",
      "‚ùå D√©j√† pr√©sent, ignor√© : https://amzn.to/4jmeIgq\n",
      "‚ùå D√©j√† pr√©sent, ignor√© : https://amzn.to/4kCwVY9\n",
      "\n",
      "‚úÖ Scraping termin√©. 0 produit(s) ajout√©(s).\n",
      "üìÑ Donn√©es enregistr√©es dans : canapes_clean.csv\n",
      "üìä Colonnes : Lien d'affiliation, Titre de l'article, Couleur, Image URL\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# --- Configuration du navigateur ---\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/122.0.0.0 Safari/537.36\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# --- Fichier CSV de destination ---\n",
    "csv_file = \"canapes_clean.csv\"\n",
    "\n",
    "# --- Liste des URLs d'affiliation √† scraper ---\n",
    "urls = [ \n",
    "\"https://amzn.to/4kAxwcV\",\n",
    "\"https://amzn.to/3SRG5nK\",\n",
    "\"https://amzn.to/3YYZOW6\",\n",
    "\"https://amzn.to/4jk2uFe\",\n",
    "\"https://amzn.to/4jmeIgq\",\n",
    "\"https://amzn.to/4kCwVY9\"\n",
    "\n",
    "]\n",
    "\n",
    "# --- Charger les URLs d√©j√† pr√©sentes dans le CSV pour √©viter les doublons ---\n",
    "produits_existants = set()\n",
    "if os.path.exists(csv_file):\n",
    "    with open(csv_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            if \"Lien d'affiliation\" in row:\n",
    "                produits_existants.add(row[\"Lien d'affiliation\"])\n",
    "\n",
    "def extract_product_title():\n",
    "    \"\"\"Extrait le titre du produit\"\"\"\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"productTitle\"))\n",
    "        )\n",
    "        return element.text.strip()\n",
    "    except (TimeoutException, NoSuchElementException):\n",
    "        return \"\"\n",
    "\n",
    "def extract_main_image():\n",
    "    \"\"\"Extrait l'URL de l'image principale\"\"\"\n",
    "    try:\n",
    "        image = WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.ID, \"landingImage\"))\n",
    "        )\n",
    "        return image.get_attribute(\"src\")\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def extract_couleur():\n",
    "    \"\"\"Extrait la couleur du produit Amazon, en essayant plusieurs m√©thodes, y compris le titre et la description.\"\"\"\n",
    "    couleurs_connues = [\n",
    "        \"noir\", \"blanc\", \"gris\", \"beige\", \"bleu\", \"vert\", \"rouge\", \"jaune\", \"marron\", \"rose\",\n",
    "        \"violet\", \"orange\", \"turquoise\", \"cr√®me\", \"ivoire\", \"chocolat\", \"anthracite\", \"taupe\",\n",
    "        \"bordeaux\", \"camel\", \"kaki\", \"argent\", \"dor√©\", \"cuivre\", \"multicolore\"\n",
    "    ]\n",
    "    # 1. M√©thode principale (variation_color_name)\n",
    "    try:\n",
    "        couleur = driver.find_element(By.CSS_SELECTOR, \"#variation_color_name .selection\")\n",
    "        if couleur.text.strip():\n",
    "            return couleur.text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    # 2. M√©thode alternative (data-feature-name)\n",
    "    try:\n",
    "        couleur = driver.find_element(By.CSS_SELECTOR, \"[data-feature-name='color_name'] .selection\")\n",
    "        if couleur.text.strip():\n",
    "            return couleur.text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    # 3. M√©thode alternative (po-color_name)\n",
    "    try:\n",
    "        couleur = driver.find_element(By.CSS_SELECTOR, \".po-color_name .po-break-word\")\n",
    "        if couleur.text.strip():\n",
    "            return couleur.text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    # 4. Chercher la couleur dans le titre\n",
    "    try:\n",
    "        titre = extract_product_title().lower()\n",
    "        for couleur in couleurs_connues:\n",
    "            if couleur in titre:\n",
    "                return couleur.capitalize()\n",
    "    except:\n",
    "        pass\n",
    "    # 5. Chercher la couleur dans la description\n",
    "    try:\n",
    "        description = \"\"\n",
    "        try:\n",
    "            description = driver.find_element(By.ID, \"productDescription\").text.lower()\n",
    "        except:\n",
    "            # Parfois la description est ailleurs\n",
    "            description = driver.find_element(By.ID, \"feature-bullets\").text.lower()\n",
    "        for couleur in couleurs_connues:\n",
    "            if couleur in description:\n",
    "                return couleur.capitalize()\n",
    "    except:\n",
    "        pass\n",
    "    # 6. Dernier recours : parenth√®ses √† la fin du titre\n",
    "    try:\n",
    "        titre = extract_product_title()\n",
    "        import re\n",
    "        match = re.search(r\"\\(([^)]+)\\)$\", titre)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    except:\n",
    "        pass\n",
    "    # 7. Rien trouv√©\n",
    "    print(\"‚ö†Ô∏è Couleur non trouv√©e pour ce produit.\")\n",
    "    return \"\"\n",
    "\n",
    "def scrape_amazon_product(url):\n",
    "    \"\"\"Scrape un produit Amazon et retourne seulement les 4 colonnes sp√©cifi√©es\"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"productTitle\")))\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Ne r√©cup√©rer que les 4 colonnes demand√©es\n",
    "        product_data = {\n",
    "            \"Lien d'affiliation\": url,\n",
    "            \"Titre de l'article\": extract_product_title(),\n",
    "            \"Couleur\": extract_couleur(),\n",
    "            \"Image URL\": extract_main_image(),\n",
    "        }\n",
    "\n",
    "        return product_data\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du scraping de {url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# --- Liste des produits √† ajouter ---\n",
    "produits = []\n",
    "\n",
    "# --- D√©finir les colonnes fixes (dans l'ordre) ---\n",
    "colonnes = [\"Lien d'affiliation\", \"Titre de l'article\", \"Couleur\", \"Image URL\"]\n",
    "\n",
    "# --- Scraping des nouvelles URLs uniquement ---\n",
    "for url in urls:\n",
    "    if url in produits_existants:\n",
    "        print(f\"‚ùå D√©j√† pr√©sent, ignor√© : {url}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        print(f\"üîç Scraping : {url}\")\n",
    "        produit = scrape_amazon_product(url)\n",
    "        if produit:\n",
    "            produits.append(produit)\n",
    "            produits_existants.add(url)\n",
    "            titre = produit.get(\"Titre de l'article\", \"\")\n",
    "            titre_court = titre[:50] if titre else \"Titre non trouv√©\"\n",
    "            print(f\"‚úÖ Ajout√© : {titre_court}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur sur {url} : {e}\")\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# --- Enregistrement final dans le fichier CSV ---\n",
    "if produits:\n",
    "    write_mode = \"a\" if os.path.exists(csv_file) else \"w\"\n",
    "    with open(csv_file, mode=write_mode, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=colonnes, quoting=csv.QUOTE_MINIMAL)\n",
    "        if write_mode == \"w\":\n",
    "            writer.writeheader()\n",
    "        for produit in produits:\n",
    "            writer.writerow(produit)\n",
    "\n",
    "print(f\"\\n‚úÖ Scraping termin√©. {len(produits)} produit(s) ajout√©(s).\")\n",
    "print(f\"üìÑ Donn√©es enregistr√©es dans : {csv_file}\")\n",
    "print(f\"üìä Colonnes : {', '.join(colonnes)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"canapes_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101 entries, 0 to 100\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Lien d'affiliation  101 non-null    object\n",
      " 1   Titre de l'article  101 non-null    object\n",
      " 2   Couleur             101 non-null    object\n",
      " 3   Image URL           101 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lien d'affiliation</th>\n",
       "      <th>Titre de l'article</th>\n",
       "      <th>Couleur</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://amzn.to/3H7ps4V</td>\n",
       "      <td>Vesgantti Canap√© 2 Places en Tissu Velours Bei...</td>\n",
       "      <td>Beige</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81ZhDwep2O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://amzn.to/3YVuAzd</td>\n",
       "      <td>Causeuse moderne, canap√© dans une bo√Æte, pas d...</td>\n",
       "      <td>Beige</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81UP1CpRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://amzn.to/4k9cNwS</td>\n",
       "      <td>Sapgaks Canap√© sectionnel en U Moderne,canap√© ...</td>\n",
       "      <td>Beige</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81UKvWfXRI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://amzn.to/3FlGD2g</td>\n",
       "      <td>Seyakany Canap√© 4 Places Moderne avec Coussins...</td>\n",
       "      <td>Beige</td>\n",
       "      <td>https://m.media-amazon.com/images/I/91w0cDj+K-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://amzn.to/43JPjZq</td>\n",
       "      <td>Guyii Tr√®s Grand Fauteuil Simple en Tissu Anti...</td>\n",
       "      <td>Beige</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81Dr4mwVER...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Lien d'affiliation                                 Titre de l'article  \\\n",
       "0  https://amzn.to/3H7ps4V  Vesgantti Canap√© 2 Places en Tissu Velours Bei...   \n",
       "1  https://amzn.to/3YVuAzd  Causeuse moderne, canap√© dans une bo√Æte, pas d...   \n",
       "2  https://amzn.to/4k9cNwS  Sapgaks Canap√© sectionnel en U Moderne,canap√© ...   \n",
       "3  https://amzn.to/3FlGD2g  Seyakany Canap√© 4 Places Moderne avec Coussins...   \n",
       "4  https://amzn.to/43JPjZq  Guyii Tr√®s Grand Fauteuil Simple en Tissu Anti...   \n",
       "\n",
       "  Couleur                                          Image URL  \n",
       "0   Beige  https://m.media-amazon.com/images/I/81ZhDwep2O...  \n",
       "1   Beige  https://m.media-amazon.com/images/I/81UP1CpRSS...  \n",
       "2   Beige  https://m.media-amazon.com/images/I/81UKvWfXRI...  \n",
       "3   Beige  https://m.media-amazon.com/images/I/91w0cDj+K-...  \n",
       "4   Beige  https://m.media-amazon.com/images/I/81Dr4mwVER...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://m.media-amazon.com/images/I/61XlIv8-plL._AC_SX522_.jpg'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Image URL\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Lien d'affiliation, dtype: object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[pd.isna(df[\"Image URL\"]), \"Lien d'affiliation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Lien d'affiliation\"] == \"https://amzn.to/4dxCSDu\", \"Couleur\"] = \"Blanc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lien d'affiliation</th>\n",
       "      <th>Titre de l'article</th>\n",
       "      <th>Couleur</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>https://amzn.to/4dxCSDu</td>\n",
       "      <td>Canap√© Jelly Bear/White Colour - En peluche do...</td>\n",
       "      <td>Blanc</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81SJT3iFls...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Lien d'affiliation  \\\n",
       "75  https://amzn.to/4dxCSDu   \n",
       "\n",
       "                                   Titre de l'article Couleur  \\\n",
       "75  Canap√© Jelly Bear/White Colour - En peluche do...   Blanc   \n",
       "\n",
       "                                            Image URL  \n",
       "75  https://m.media-amazon.com/images/I/81SJT3iFls...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"Lien d'affiliation\"] == \"https://amzn.to/4dxCSDu\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"canapes_clean.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
